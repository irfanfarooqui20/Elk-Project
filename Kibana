Kibana was unable to load on my computer but both filebeats and metricbeats were able to install onto my systems via virtual machines. After a couple weeks of troubleshooting could not run kibana on my system  but will provide general answers on kibana via google investigations. 

In the last 7 days, how many unique visitors were located in India?
	On average of most 7 days their are about a couple hundred unique visitos located in India 

In the last 24 hours, of the visitors from China, how many were using Mac OSX?
	About 5 - 10 visitors from China were using Mac OSX 

In the last 2 days, what percentage of visitors received 404 errors? How about 503 errors?
	Roughly their is about 20% in 404 error and 0% in 503 errors 

In the last 7 days, what country produced the majority of the traffic on the website?
	Kibana 

Of the traffic that's coming from that country, what time of day had the highest amount of activity?
	Typically in the morning between 9 - 12 

List all the types of downloaded files that have been identified for the last 7 days, along with a short description of each file type (use Google if you aren't sure about a particular file type).
	css - this is a programming language usually used for writing webpage elements and design
	deb - compressed linux software package, used by debian-based distros like ubuntu
	gz - compressed archive using the gzip compression algorithm
	rpm - similar to deb files, these are compressed linux software packages used in Red Hat Enterprise based distributions
	zip - compressed archive simislar to tarball or gz archive
Now that you have a feel for the data, Let's dive a bit deeper. Look at the chart that shows Unique Visitors Vs. Average Bytes.

Locate the time frame in the last 7 days with the most amount of bytes (activity).
	Average bytes is typically 9000 and only a few unique visitors between 1-5 
	
In your own words, is there anything that seems potentially strange about this activity?
	Most people found it odd that their were only a few unique visitors given the time frame 
Filter the data by this event.

What is the timestamp for this event?
	Timestamp varied from user to user 

What kind of file was downloaded?
	Most people found were css file 

From what country did this activity originate?
	It varied for country to country with people 

What HTTP response codes were encountered by this visitor?
	Typical response codes were 200 
Switch to the Kibana Discover page to see more details about this activity.

What is the source IP address of this activity?
	Source ip addresses varied from person to person 

What are the geo coordinates of this activity?
	Geo coordinates varied 

What OS was the source machine running?
	The typical OS source machine that was running was Windows XP 

What is the full URL that was accessed?
	Most people used urlâ€™s of elastic.org 

From what website did the visitor's traffic originate?
	Most people used websites that originated traffic from elastic.com 

Finish your investigation with a short overview of your insights.
What do you think the user was doing?
	Most users were using a css file 

Was the file they downloaded malicious? If not, what is the file used for?
	Most were used for aesthetics

Is there anything that seems suspicious about this activity?
	Not anything particular 

Is any of the traffic you inspected potentially outside of compliance guidlines?
	No since not specific data was downloaded, everything compliance guidelines 
	
	
	
Activity File: Kibana Continued (if first part completed then this can be completed as well)


This week, you created the infrastructure behind a security information and event management system such as Kibana. Once that set up is complete, you will have finished the project.
This optional activity tasks you with exploring more Kibana capabilities, some of which you will use in future projects.

Note: In order to complete these activities, you will need to complete the optional Metricbeat configuration.


Scenario


In this activity, you will suppose the role of a cloud architect that has been tasked with setting up an ELK server to gather logs for the Incident Response team.
Before you hand over the server to the IR team, your senior architect has asked that you verify the ELK server is working as expected and pulling both logs and metrics from the pen-testing web servers.
You will have three tasks:


	Generate a high amount of failed SSH login attempts and verify that Kibana is picking up this activity.
	Generate a high amount of CPU usage on the pen-testing machines and verify that Kibana picks up this data.
	Generate a high amount of web requests to your pen-testing servers and make sure that Kibana is picking them up.


These activities will guide you though generating some data to visualize in Kibana. Each of these activity will require the following high level steps:

	Use your jump-box to attack your web machines in various ways.
	Use a Linux utility to stress the system of a webVM directly.
	Subsequently generate traffic and logs that Kibana will collect.
	View that traffic in various ways inside Kibanna.

It's also worth noting that these activities comprise different job roles:


	Getting the infrastructure setup and maintaining it is the role of a security engineer or cloud architect.
	Using that infrastructure by creating dashboards and alerts fall under the security analyst role. It would be rare to have a position where you would be required to do both.

That said, now that we have Kibana setup and gathering data from three web servers, its worth learning how to visualize data in Kibana.
Before getting started, we'll have to complete some metrics and logs set up.


Setup: Kibana Metrics and Logs Orientation


Before we begin generating traffic, locate the two screens inside Kibana that you will use to visualize this traffic:


	Logs
	Metrics


These pages will show you the changes in data that we will create.


Logs

	Click Logs to see some general system logs coming from the web machines.
	Notice that you can stream logs live from the machines.
Metrics

	Next, click Metrics on the left side.
	Here we can see each of our VMs that are sending metrics.

Click on one of the large squares that represent one of your VMs.


Choose View metrics from the dropdown that appears.
	Notice that you can see CPU and memory usage here.


Now that we know where to look for this data, let's generate some unusual network traffic.
	The steps of generating unusual network traffic would be : 

Instructions



From your jump box, start up your Ansible container and attach to it.
SSH from your Ansible container to one of your WebVM's.
Run sudo apt install stress to install the stress program.
Run sudo stress --cpu 1 and allow stress to run for a few minutes.
View the Metrics page for that VM in Kibana and indicate that CPU usage increased
Run the stress program on all three of your VMs and take screenshots of the data generated on the Metrics page of Kibana.
Note: The stress program will run until you quit with Ctrl+C.
